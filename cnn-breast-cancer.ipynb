{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Import libraries**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport os \nfrom os import listdir\nfrom tqdm import tqdm\nimport shutil\n\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\nfrom keras.utils import np_utils, to_categorical\nfrom keras.preprocessing import image\n\n%matplotlib inline\n#************************************************","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Read DataBase**","metadata":{}},{"cell_type":"code","source":"os.mkdir('augmented')\nos.mkdir('/kaggle/working/augmented/benign')\nos.mkdir('/kaggle/working/augmented/malignant')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getListOfFiles(dirName):\n    listOfFile = os.listdir(dirName)\n    allFiles = list()\n    for entry in listOfFile:\n        fullPath = os.path.join(dirName, entry)\n        if os.path.isdir(fullPath):\n            allFiles = allFiles + getListOfFiles(fullPath)\n        else:\n            allFiles.append(fullPath)\n                \n    return allFiles","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"files_benign = getListOfFiles('../input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/benign')\nfor f in files_benign:\n    if f.endswith('.png'):\n        \n        shutil.copy(f,'augmented/benign')\nfiles_malignant = getListOfFiles('../input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/malignant')\nfor f in files_malignant:\n    if f.endswith('.png'):\n        \n        shutil.copy(f,'augmented/malignant')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"benign_images = getListOfFiles('/kaggle/working/augmented/benign')\nmalignent_images = getListOfFiles('/kaggle/working/augmented/malignant')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Visualization**","metadata":{}},{"cell_type":"markdown","source":"**Benign slide image**","metadata":{}},{"cell_type":"code","source":"image.load_img(benign_images[3], target_size=(120,120,1), grayscale=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Malignant slide image**","metadata":{}},{"cell_type":"code","source":"image.load_img(malignent_images[3], target_size=(120,120,1), grayscale=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_images = len(benign_images) + len(malignent_images)\ntotal_images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.DataFrame(index=np.arange(0, len(benign_images)+len(malignent_images)), columns=[\"image\", \"target\"])\nk=0\n\nfor c in [0,1]:\n        if c==1:\n            for m in range(len(benign_images)):\n                data.iloc[k][\"image\"] = benign_images[m]\n                data.iloc[k][\"target\"] = 0\n                k += 1\n        else:\n            for m in range(len(malignent_images)):\n                data.iloc[k][\"image\"] = malignent_images[m]\n                data.iloc[k][\"target\"] = 1\n                k += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Check unbalanced data**","metadata":{}},{"cell_type":"code","source":"count_data = data[\"target\"].value_counts()\ncount_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\ntarget = sns.countplot(data[\"target\"])\ntarget.set_xticklabels(['0','1'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ben_upsampled = resample(data[data['target']==0],n_samples=data[data['target']==1].shape[0], random_state=42)\n\nup_sampled = pd.concat([data[data['target']==1], ben_upsampled])\n\nup_sampled['target'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ben_upsampled.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"up_sampled.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image = []\ny = []\n\nfor i in tqdm(range(up_sampled.shape[0])):\n    img = image.load_img(up_sampled['image'].iloc[i], target_size=(28,28,1), grayscale=False)\n    img = image.img_to_array(img)\n    img = img/255\n    train_image.append(img)\n\n        \nX = np.array(train_image)\ny = up_sampled.iloc[:,-1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\nX_test, X_val, y_test, y_val = train_test_split(X_test, y_test, random_state=42, test_size=0.2 , shuffle=True)\n\nY_train = np_utils.to_categorical(y_train, 2)\nY_test = np_utils.to_categorical(y_test, 2)\nY_val = np_utils.to_categorical(y_val, 2)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(X_val.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n#convlouton layer with the number of filters, filter size, strides steps, padding or no, activation type and the input shape.\nmodel.add(Conv2D(30, kernel_size = (3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,3)))\n#pooling layer to reduce the volume of input image after convolution,\nmodel.add(MaxPool2D(pool_size=(1,1)))\n#flatten layer to flatten the output\nmodel.add(Flatten())   # flatten output of conv\nmodel.add(Dense(150, activation='relu'))  # hidden layer of 150 neuron\nmodel.add(Dense(2, activation='softmax'))  # output layer\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n\nhistory = model.fit(X_train, Y_train, batch_size=20, epochs = 20, validation_data=(X_test, Y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_df = pd.DataFrame(history.history)\nhistory_df.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict_classes(X_val)\nacc_test = 0\n\nfor i in range(X_val.shape[0]):\n    if(y_pred[i] == y_val[i]):\n        acc_test= acc_test+1\nprint(\"Accuracy test : \"  , acc_test/X_val.shape[0]*100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}